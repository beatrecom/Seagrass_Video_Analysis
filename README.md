# Seeing the Seafloor Smarter  
## Using AI to Classify Seagrass from ASV Video

### Expanded Summary  
As part of a COMIT-supported research effort, Bea Combs-Hintze has developed an image-recognition system and training database that transforms hours of underwater video footage from autonomous surface vessels (ASVs) into searchable, structured seagrass data.

- **Habitat Features Identified**  
  - Seagrass presence  
  - Species type (e.g., *Thalassia*, *Syringodium*)  
  - Canopy density  
  - Structural complexity  
- **Data Fusion**  
  - Video frames are georeferenced and time-synced with acoustic sonar data (e.g., multibeam backscatter)  
  - Enables visual confirmation and sonar-based prediction of seagrass structures  

---

### How It Works  
1. **Data Collection**  
   ASV surveys gather synchronized sonar and HD video in shallow coastal zones.  
2. **Frame Extraction & Annotation**  
   Video is broken into still frames, then annotated using seagrass ID guides.  
3. **Database Building**  
   Labeled images populate a growing library of known visual features.  
4. **Model Training**  
   Machine-learning algorithms learn to ask:  
   - Is it seagrass?  
   - Which species?  
   - How dense is the canopy?  
5. **Integrated Output**  
   Researchers can rapidly process new video, linking each observation directly to its acoustic signature.

---

### Why This Matters  
- **Faster**  
  Cuts down on tedious, frame-by-frame manual review.  
- **Smarter**  
  Improves accuracy of sonar models with real-world visual training data.  
- **Scalable**  
  Enables broader habitat classification across vast coastal areas.  
- **Educational**  
  Serves as a hands-on tool for interns and early-career scientists.

---

*By merging AI-driven image recognition with georeferenced sonar, this system sets the stage for fully automated seagrass mapping—where one day sonar alone, informed by AI, will unveil the seafloor’s hidden tapestry.*  
